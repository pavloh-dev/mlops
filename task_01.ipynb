{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cff981c0-2121-4a0e-886f-2bd5065ad3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task description: https://github.com/DataTalksClub/mlops-zoomcamp/blob/main/cohorts/2024/01-intro/homework.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4424533b-2a07-433a-b349-4429dd590e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\kiev-\\ideaprojects\\untitled\\venv\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: sklearn in c:\\users\\kiev-\\ideaprojects\\untitled\\venv\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: pyarrow in c:\\users\\kiev-\\ideaprojects\\untitled\\venv\\lib\\site-packages (19.0.1)\n",
      "Requirement already satisfied: fastparquet in c:\\users\\kiev-\\ideaprojects\\untitled\\venv\\lib\\site-packages (2024.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\kiev-\\ideaprojects\\untitled\\venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\kiev-\\ideaprojects\\untitled\\venv\\lib\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: numpy>=1.22.4 in c:\\users\\kiev-\\ideaprojects\\untitled\\venv\\lib\\site-packages (from pandas) (1.26.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\kiev-\\ideaprojects\\untitled\\venv\\lib\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\kiev-\\ideaprojects\\untitled\\venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\kiev-\\ideaprojects\\untitled\\venv\\lib\\site-packages (from sklearn) (1.2.2)\n",
      "Requirement already satisfied: cramjam>=2.3 in c:\\users\\kiev-\\ideaprojects\\untitled\\venv\\lib\\site-packages (from fastparquet) (2.9.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\kiev-\\ideaprojects\\untitled\\venv\\lib\\site-packages (from fastparquet) (24.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\kiev-\\ideaprojects\\untitled\\venv\\lib\\site-packages (from fastparquet) (2024.10.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\kiev-\\ideaprojects\\untitled\\venv\\lib\\site-packages (from scikit-learn->sklearn) (3.5.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\kiev-\\ideaprojects\\untitled\\venv\\lib\\site-packages (from scikit-learn->sklearn) (1.4.2)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\kiev-\\ideaprojects\\untitled\\venv\\lib\\site-packages (from scikit-learn->sklearn) (1.14.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.1.2; however, version 25.0.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\kiev-\\IdeaProjects\\untitled\\venv\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas sklearn pyarrow fastparquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3838a560-a0e4-48fc-91eb-201e820b937e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Load the dataset for January 2023\n",
    "green_dataset = \"green_tripdata_2023-01.parquet\"\n",
    "yellow_dataset = \"yellow_tripdata_2023-01.parquet\"\n",
    "\n",
    "df_train = pd.read_parquet(green_dataset)\n",
    "df_val = pd.read_parquet(yellow_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3428c5db-fd3e-4242-9152-69ef4b897b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['VendorID', 'lpep_pickup_datetime', 'lpep_dropoff_datetime', 'store_and_fwd_flag', 'RatecodeID', 'PULocationID', 'DOLocationID', 'passenger_count', 'trip_distance', 'fare_amount', 'extra', 'mta_tax', 'tip_amount', 'tolls_amount', 'ehail_fee', 'improvement_surcharge', 'total_amount', 'payment_type', 'trip_type', 'congestion_surcharge']\n",
      "['VendorID', 'tpep_pickup_datetime', 'tpep_dropoff_datetime', 'passenger_count', 'trip_distance', 'RatecodeID', 'store_and_fwd_flag', 'PULocationID', 'DOLocationID', 'payment_type', 'fare_amount', 'extra', 'mta_tax', 'tip_amount', 'tolls_amount', 'improvement_surcharge', 'total_amount', 'congestion_surcharge', 'airport_fee']\n",
      "Number of columns in January taxi dataset #1: 20\n",
      "Number of columns in January taxi dataset #2: 19\n"
     ]
    }
   ],
   "source": [
    "# STep 1: Define a number of columns (EDA)\n",
    "print(df_train.columns.tolist())\n",
    "print(df_val.columns.tolist())\n",
    "print(f\"Number of columns in January taxi dataset #1: {df_train.shape[1]}\")\n",
    "print(f\"Number of columns in January taxi dataset #2: {df_val.shape[1]}\")\n",
    "\n",
    "\n",
    "pickup_col = 'tpep_pickup_datetime' if 'tpep_pickup_datetime' in df_train.columns else 'lpep_pickup_datetime'\n",
    "dropoff_col = 'tpep_dropoff_datetime' if 'tpep_dropoff_datetime' in df_train.columns else 'lpep_dropoff_datetime'\n",
    "\n",
    "df_train[pickup_col] = pd.to_datetime(df_train[pickup_col])\n",
    "df_train[dropoff_col] = pd.to_datetime(df_train[dropoff_col])\n",
    "\n",
    "# Compute trip duration in minutes.\n",
    "df_train['duration'] = (df_train[dropoff_col] - df_train[pickup_col]).dt.total_seconds() / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "573a3136-bcd4-4f82-bb7d-9df5fbcdda86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q2. Standard deviation of trip duration (in minutes): 74.93\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 2. Compute the standard deviation of the trip duration.\n",
    "std_duration = df_train['duration'].std()\n",
    "print(\"Q2. Standard deviation of trip duration (in minutes):\", round(std_duration, 2))\n",
    "# Expected answer: approximately 42.59"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8944a7b-fe48-4bec-8647-50522b7620af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q3. Fraction of records left after dropping outliers: 97.0%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Step 3. Drop Outliers ---\n",
    "# Keep only rides with a duration between 1 and 60 minutes (inclusive).\n",
    "mask = (df_train['duration'] >= 1) & (df_train['duration'] <= 60)\n",
    "df_train_filtered = df_train[mask].copy()\n",
    "\n",
    "# Calculate the fraction of records remaining after dropping outliers.\n",
    "fraction_remaining = len(df_train_filtered) / len(df_train)\n",
    "print(\"Q3. Fraction of records left after dropping outliers:\", f\"{round(fraction_remaining * 100, 0)}%\")\n",
    "# Expected answer: ~95%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3af9e65-2f2e-452d-87f5-7f04d709ef08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q4. Dimensionality of the one-hot encoded matrix: 467\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Step 4. One-Hot Encoding ---\n",
    "# Convert pickup and dropoff location IDs to strings.\n",
    "df_train_filtered['PULocationID'] = df_train_filtered['PULocationID'].astype(str)\n",
    "df_train_filtered['DOLocationID'] = df_train_filtered['DOLocationID'].astype(str)\n",
    "\n",
    "# Create a list of dictionaries from the two features.\n",
    "dicts_train = df_train_filtered[['PULocationID', 'DOLocationID']].to_dict(orient='records')\n",
    "\n",
    "# Initialize and fit a DictVectorizer.\n",
    "dv = DictVectorizer()\n",
    "X_train = dv.fit_transform(dicts_train)\n",
    "\n",
    "# Q4. Get the dimensionality of the feature matrix.\n",
    "print(\"Q4. Dimensionality of the one-hot encoded matrix:\", X_train.shape[1])\n",
    "# Expected answer: 515 columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6b53fe9-805e-482f-9ba8-f80b4f1c964d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q5. Training RMSE: 7.04\n"
     ]
    }
   ],
   "source": [
    "# --- Step 5. Training a Model ---\n",
    "# Set the target variable.\n",
    "y_train = df_train_filtered['duration'].values\n",
    "\n",
    "# Train a linear regression model.\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# Compute the RMSE on the training data.\n",
    "y_pred_train = lr.predict(X_train)\n",
    "rmse_train = mean_squared_error(y_train, y_pred_train, squared=False)\n",
    "print(\"Q5. Training RMSE:\", round(rmse_train, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47eb2c2d-9c46-4d55-a0c6-a359524729ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q6. Validation RMSE: 18.01\n"
     ]
    }
   ],
   "source": [
    "# --- Step 6. Evaluating the Model on Validation Data (February 2023) ---\n",
    "# Process the validation dataset similarly.\n",
    "pickup_col_val = 'tpep_pickup_datetime' if 'tpep_pickup_datetime' in df_val.columns else 'lpep_pickup_datetime'\n",
    "dropoff_col_val = 'tpep_dropoff_datetime' if 'tpep_dropoff_datetime' in df_val.columns else 'lpep_dropoff_datetime'\n",
    "\n",
    "df_val[pickup_col_val] = pd.to_datetime(df_val[pickup_col_val])\n",
    "df_val[dropoff_col_val] = pd.to_datetime(df_val[dropoff_col_val])\n",
    "df_val['duration'] = (df_val[dropoff_col_val] - df_val[pickup_col_val]).dt.total_seconds() / 60\n",
    "\n",
    "# Drop outliers in the validation set.\n",
    "mask_val = (df_val['duration'] >= 1) & (df_val['duration'] <= 60)\n",
    "df_val_filtered = df_val[mask_val].copy()\n",
    "\n",
    "# Convert location IDs to strings.\n",
    "df_val_filtered['PULocationID'] = df_val_filtered['PULocationID'].astype(str)\n",
    "df_val_filtered['DOLocationID'] = df_val_filtered['DOLocationID'].astype(str)\n",
    "\n",
    "# Transform the validation data using the previously fitted DictVectorizer.\n",
    "dicts_val = df_val_filtered[['PULocationID', 'DOLocationID']].to_dict(orient='records')\n",
    "X_val = dv.transform(dicts_val)\n",
    "y_val = df_val_filtered['duration'].values\n",
    "\n",
    "# Compute predictions and RMSE on the validation dataset.\n",
    "y_pred_val = lr.predict(X_val)\n",
    "rmse_val = mean_squared_error(y_val, y_pred_val, squared=False)\n",
    "print(\"Q6. Validation RMSE:\", round(rmse_val, 2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
